<!DOCTYPE HTML>
<html>
	<head>
		<title>Fourth AAAI Workshop on Privacy-Preserving Artificial Intelligence</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="keywords" content="PPAI,PPAI23,PPAI2023,PPAI 23,PPAI 2023,AAAI,AAAI23,AAAI 2023,Privacy Preserving AI,Privacy Preserving Artificial Intelligence,AI, Differential Privacy,Privacy,Preserving,Artificial,Intelligence"/>
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">
				<!-- Main -->
				<div id="main">
					<div class="inner">
						<!-- Banner -->
						<section id="banner">
							<div class="content">
								<header>
									<h1>The Fourth AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-23)</h1>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-calendar3" viewBox="0 0 16 16">
									  <path d="M14 0H2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2zM1 3.857C1 3.384 1.448 3 2 3h12c.552 0 1 .384 1 .857v10.286c0 .473-.448.857-1 .857H2c-.552 0-1-.384-1-.857V3.857z"/>
									  <path d="M6.5 7a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm-9 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm-9 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2zm3 0a1 1 0 1 0 0-2 1 1 0 0 0 0 2z"/>
									</svg>									
									February 13, 2023
<!-- 									<br>									
                                		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="mr-1 bi bi-geo-alt" viewBox="0 0 16 16">
                                  		<path d="M12.166 8.94c-.524 1.062-1.234 2.12-1.96 3.07A31.493 31.493 0 0 1 8 14.58a31.481 31.481 0 0 1-2.206-2.57c-.726-.95-1.436-2.008-1.96-3.07C3.304 7.867 3 6.862 3 6a5 5 0 0 1 10 0c0 .862-.305 1.867-.834 2.94zM8 16s6-5.686 6-10A6 6 0 0 0 2 6c0 4.314 6 10 6 10z"/>
                                  		<path d="M8 8a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm0 1a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
                                		</svg> 	
                                		<a href="https://aaai-2023.virtualchair.net/index.html">Enter Virtual Venue</a>
                              		 Room: Blue 2
 -->                              		 <!-- https://link.virtualchair.net/aaai-23/eePCFG6B4iJGpnRrBadr/Blue2 -->
								</header>
							</div>
							<span class="center">
								<img class="center" src="images/logo-ppai.png" alt=""/>
						</section>

						<!-- Section -->
						<section>
							<header class="major" id="scope">
								<h2>Scope and Topics</h2>
							</header>
							<p>

							The availability of massive amounts of data, coupled with high-performance cloud computing 
							platforms, has driven significant progress in artificial intelligence and, in particular, 
							machine learning and optimization. It has profoundly impacted several areas, including computer 
							vision, natural language processing, and transportation. However, the use of rich data sets 
							also raises significant privacy concerns: They often reveal personal sensitive information 
							that can be exploited, without the knowledge and/or consent of the involved individuals, for 
							various purposes including monitoring, discrimination, and illegal activities. 
							<br>
							In its fourth edition the, AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-23) 
							provides a platform for researchers, AI practitioners, and policymakers to discuss technical 
							and societal issues and present solutions related to privacy in AI applications. 
							The workshop will focus on both the theoretical and practical challenges related to the design 
							of privacy-preserving AI systems and algorithms and will have strong multidisciplinary 
							components, including soliciting contributions about policy, legal issues, and societal 
							impact of privacy in AI. 
							</p>
							PPAI-23 will place particular emphasis on: 
							<ol>
								<li>Algorithmic approaches to protect data privacy in the context of learning, 
									optimization, and decision making that raise fundamental challenges for 
								existing technologies.</li> 
								<li>Social issues related to tracking, tracing, and surveillance programs.</li> 
								<li>Algorithms and frameworks to release privacy-preserving benchmarks and data sets.</li> 
							</ol>

							<h3>Topics</h3>
							The workshop organizers invite paper submissions on the following (and related) topics:
							<ul>
							 <li>Applications of privacy-preserving AI systems</li>
							 <li>Attacks on data privacy</li>
							 <li>Differential privacy: theory and applications</li>
							 <li>Distributed privacy-preserving algorithms</li>
							 <li>Privacy-preserving Federated learning</li>
							 <li>Human rights and privacy</li>
							 <li>Privacy and Fairness</li>
							 <li>Privacy and causality </li>
							 <li>Privacy-preserving optimization and machine learning</li>
							 <li>Privacy-preserving test cases and benchmarks</li>
							 <li>Surveillance and societal issues</li>
							</ul>
							<p>
								Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and data sets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples. 
							</p>

							<h3>Format</h3> 

							<p> 
								The workshop will be a one-day  meeting.  
								The workshop will include a number of technical  sessions, a 
								poster session where presenters can discuss their work, with
								the aim of  further fostering collaborations, multiple invited
								speakers covering crucial challenges for  the field of
								privacy-preserving AI applications, including policy and
								societal impacts, a number of tutorial talks, and will
								conclude with a panel discussion.  
	 						</p>

						<br>

						<header class="major" id="dates">
								<h2>Important Dates</h2>
							</header>
							<ul>
							<li><strong>November 21, 2022</strong> – Submission Deadline <font color="#f56a6a">[Extended]</font></li>
							<li><strong>November 21, 2022</strong>  – NeurIPS/AAAI Fast Track Submission Deadline <font color="#f56a6a">[Extended]</font></li>
							<!-- <li><strong>November 19, 2022</strong> – AAAI Early registration deadline</li> -->
							<li><strong>January 2, 2022</strong> – Acceptance Notification</li>
							<li><strong>January 10, 2023</strong> – Student Scholarship Program Deadline</li>
							<li><strong>February 13, 2023</strong> – Workshop Date </li>
							</ul>

						<br>

							<header class="major" id="submission">
								<h2>Submission Information</h2>
							</header>

							<p>
							Submission URL:  <a href="https://cmt3.research.microsoft.com/PPAI2023">https://cmt3.research.microsoft.com/PPAI2023</a>
							</p>

							<h3>Submission Types</h3>
							<ul>
								<li><strong>Technical Papers</strong>: 
								Full-length research papers of up to 7 pages (excluding references and appendices) 
								detailing high quality work in progress or work that could potentially be published at 
								a major conference. 
								</li>
								<li><strong>Short Papers</strong>: 
								Position or short papers of up to 4 pages (excluding references and appendices) that 
								describe initial work or the release of privacy-preserving benchmarks and datasets on the 
								topics of interest. 
								</li>
							</ul>

							<h4>NeurIPS/AAAI Fast Track (Rejected AAAI papers)</h4>
							<p>
							Rejected NeurIPS/AAAI papers with *average* scores of <strong>at least 4.0</strong> 
							may be submitted directly to PPAI 
							along with previous reviews. These submissions may go through a light review process or 
							accepted if the provided reviews are judged to meet the workshop standard. 
							</p>

							<p>	
							All papers must be submitted in PDF format, using the <a href="https://www.aaai.org/Publications/Templates/AuthorKit23.zip">AAAI-23 author kit</a>. 
							Submissions should include the name(s), affiliations, and email addresses of all authors. 
							<br>
							Submissions will be refereed on the basis of technical quality, novelty, significance, and 
							clarity. Each submission will be thoroughly reviewed by at least two program committee members.
							</p>
							<p>
							NeurIPS/AAAI fast track papers are subject to the same page limits of standard submissions.
							Fast track papers should be accompanied by their reviews, submitted as a supplemental material. 
							<!-- Papers will be selected for oral and/or poster presentation at the workshop.  -->
							</p>

							<p>
							For questions about the submission process, contact the workshop <a href="#contact">chairs</a>.
							</p>

						<br>

	                       <header class="major" id="scholarship">
							<h2>PPAI-23 scholarship application</h2>
						    </header>
						    <p>PPAI is pleased to announce a Student scholarship program for 2023. The program provides partial 
						    	travel support for students who are full-time undergraduate or graduate students at colleges and universities; 
						    	have submitted papers to the workshop program or letters of recommendation from their faculty advisor. 
						   		<br><br>
						   		Preference will be given to participating students presenting papers at the workshop or to students from underrepresented countries and communities.
						    </p>
						    <p>To participate please fill in the <a href="https://forms.gle/kvqRmzNrdY75Fg8B6" target="blank">Student Scholarship Program application form</a>.</p>
						    <p>Deadline: January, 10, 2023.</p>

						    <br>

	                       <header class="major" id="registration">
							<h2>Registration</h2>
						    </header>
						    Registration in each workshop is required by all active participants, and is also open to all interested individuals.
						    <strong>Early registration deadline is on January 6th</strong>. For more information please refer to 
						    <a href="https://aaai.org/Conferences/AAAI-23/ws23/">AAAI-23 Workshop page</a>.
						</section>

					<section>
							<header class="major" id="program">
								<h2>Program (Tentative)</h2>
							</header>
						<p>
							The program will be finalized in the weeks to come. <br>
						</p>

							All times are in Eastern Standard Time (UTC-5).</br><br>



							<div class="table-wrapper">
								<table>
									<thead>
										<tr>
											<th colspan="1">Time</th>
											<th>Talk / Presenter </th>
										</tr>
									</thead>
									<tbody>
										<tr><td>8:50</td>	<td>Introductory remarks</td></tr>
										<tr><td>9:05</td>	<td><a href="#borja">Invited Talk</a>: Privacy in Image Classification Models: Informed Attacks and Practical Defenses by <em>Borja Balle</em></td> </tr>
										<!-- <tr height="8px"> -->
										<!-- <td colspan="3">Session chair: <em></em></td></tr> -->
										<tr><td>9:40</td>	<td><a href="#sp1">Spotlight Talk</a>: An Empirical Analysis of Fairness Notions under Differential Privacy</td></tr>
										<tr><td>9:50</td>	<td><a href="#sp2">Spotlight Talk</a>: Private Ad Modeling with DP-SGD</td></tr>
										<tr><td>10:00</td>	<td><a href="#sp3">Spotlight Talk</a>: Marich: A Query-efficient Distributionally-Equivalent Model Extraction Attack using Public Data</td></tr>
										<tr><td>10:10</td>	<td><a href="#jon">Invited Talk</a>: Firm Foundations for Private Machine Learning and Statistics by <em>Jonathan Ullman</em></td> </tr>

										<tr><td>10:45</td>  <td colspan="2">Break</td></tr>

										<!-- <td colspan="3">Session chair: <em></em></td></tr> -->
										<tr><td>11:00</td>	<td><a href="#sp5">Spotlight Talk</a>: SF-PATE: Scalable, Fair, and Private Aggregation of Teacher Ensembles</td></tr>
										<tr><td>11:10</td>	<td><a href="#sp6">Spotlight Talk</a>: Detecting Per-Query Gaps for Differentially Private Synthetic Data</td></tr>
										<tr><td>11:20</td>	<td><a href="#sp6">Spotlight Talk</a>: Practical Generalizability of DP Synthetic Data Mechanisms</td></tr>
										<tr><td>11:30</td>	<td><a href="#tutorial">Tutorial</a>: Using and Contributing to the OpenDP Library</td></tr>
										<tr><td>13:00</td>  <td colspan="2">Lunch Break</td></tr>

										<!-- <tr><td>14:00</td>	<td>Flash Poster Presentations</td></tr> -->
										<tr><td>14:05</td>	<td><a href="#christine">Invited Talk</a>: TBA by <em>Christine Task</em></td> </tr>
										<tr><td>14:40</td>	<td><a href="#sp5">Spotlight Talk</a>: Recycling Scraps: Improving Private Learning by Leveraging Intermediate Checkpoints</td></tr>
										<tr><td>14:50</td>	<td><a href="#sp6">Spotlight Talk</a>: MetaVerSe: Federated Meta-Learning for Versatile and Secure Representations with Dynamic Margins in Embedding Space</td></tr>
										<tr><td>15:00</td>	<td><a href="#sp6">Spotlight Talk</a>: Pushing the Boundaries of Private, Large-Scale Query Answering with RAP</td></tr>
										<tr><td>15:10</td>	<td><a href="#kobbi">Invited Talk</a>: TBA by <em>Kobbi Nissim</em></td> </tr>
										<tr><td>15:45</td>  <td colspan="2">Break</td></tr>
										
										<tr><td>16:00</td>  <td><a href="#panel">Panel Discussion</a>: Differential Privacy in real-world deployments: Where are we and what are we missing?</td></tr>
										<tr><td>16:45</td>  <td colspan="2">Concluding Remarks and Poster Session</td></tr>
										<tr><td>18:00</td>  <td colspan="2">End of the Workshop</td></tr>
									</tbody>
								</table>
							</div>
					</section>
					
					<section>
							<header class="major" id="accepted_papers">
								<h3>Accepted Papers</h3>
							</header>

								<h5 id="spotlight">Spotlight Presentations</h5>
								<ul>
								
									<li><font color="#f56a6a">An Empirical Analysis of Fairness Notions under Differential Privacy</font>
<!-- 										<a href="files/31.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://web.ecs.syr.edu/~ffiorett/cfp/PPAI22/31.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2202.12058" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
 -->									<br>
									<em>Anderson S de Oliveira (SAP)*; Caelin Kaplan (SAP); Khawla Mallat (SAP); Tanmay Chakraborty (SAP)</em>
									</li>									

									<li><font color="#f56a6a">Private Ad Modeling with DP-SGD</font><br>
									<em>Carson Denison (Google); Badih Ghazi (Google); Pritish Kamath (Google Research); Ravi Kumar (Google); Pasin Manurangsi (Google); Krishna Giri Narra (Google); Amer Sinha (Google); Avinash Varadarajan (Google AI Healthcare); Chiyuan Zhang (Google)*</em>
									</li>

									<li><font color="#f56a6a">Marich: A Query-efficient Distributionally-Equivalent Model Extraction Attack using Public Data</font><br>
									<em>Pratik Karmakar (RKMVERI, Belur, India); Debabrota Basu (Inria)*</em>
									</li>

									<li><font color="#f56a6a">SF-PATE: Scalable, Fair, and Private Aggregation of Teacher Ensembles</font><br>
									<em>Cuong Tran (Syracuse University)*; Ferdinando Fioretto (Syracuse University); Keyu Zhu (Georgia Tech); Pascal Van Hentenryck (Georgia Institute of Technology)</em>
									</li>

									<li><font color="#f56a6a">Detecting Per-Query Gaps for Differentially Private Synthetic Data</font><br>
									<em>Shweta Patwa (Duke University)*; Danyu Sun (Duke University); Amir Gilad (Duke University); Ashwin Machanavajjhala (Duke); Sudeepa Roy (Duke University, USA)</em>
									</li>

									<li><font color="#f56a6a">Pushing the Boundaries of Private, Large-Scale Query Answering with RAP</font><br>
									<em>Brendan Avent (University of Southern California)*; Aleksandra Korolova (Princeton University)</em>
									</li>

									<li><font color="#f56a6a">Recycling Scraps: Improving Private Learning by Leveraging Intermediate Checkpoints</font><br>
									<em>Virat Shejwalkar (UMass Amherst)*; Arun Ganesh (Google); Rajiv Mathews (Google); Om Thakkar (Google); Abhradeep Thakurta (Google)</em>
									</li>

									<li><font color="#f56a6a">Practical Generalizability of DP Synthetic Data Mechanisms</font><br>
									<em>Brendan Avent (University of Southern California)*; Aleksandra Korolova (Princeton University)</em>
									</li>

									<li><font color="#f56a6a">MetaVerSe: Federated Meta-Learning for Versatile and Secure Representations with Dynamic Margins in Embedding Space</font><br>
									<em>Jin Hyuk Lim (Ulsan National Institute of Science and Technology)*; Sung Whan Yoon (Ulsan National Institute of Science and Technology (UNIST))</em>
									</li>
								</ul>

								<h5>Poster Presentations</h5>
								<ul>
									<li><font color="#f56a6a">Tumult Analytics: a Robust, Easy-to-use, Scalable, and Expressive Framework for Differential Privacy</font><br>
									<em>Skye Berghel (Tumult Labs); Philip Bohannon (Tumult Labs); Damien Desfontaines (Tumult Labs)*; Charles Estes (Tumult Labs); Sam Haney (Tumult Labs); Luke Hartman (Tumult Labs); Michael Hay (Tumult Labs); Ashwin Machanavajjhala (Tumult Labs); Tom Magerlein (Tumult Labs); Gerome Miklau (Tumult Labs); Amritha Pai (Tumult Labs); William Sexton (Tumult Labs); Ruchit Shrestha (Tumult Labs)	</em>
									</li>

									<li><font color="#f56a6a">Label Inference Attack against Regression Model under Split Learning</font><br>
									<em>Shangyu Xie (Illinois Institute of Technology)*; Xin Yang (ByteDance Inc.); Yuanshun Yao (ByteDance); Tianyi Liu (ByteDance); Taiqing Wang (ByteDance Ltd); Jiankai Sun (ByteDance)	</em>
									</li>

									<li><font color="#f56a6a">Approximate, Adapt, Anonymize (3A): a Framework for Privacy Preserving Training Data Release for Machine Learning</font><br>
									<em>Tamas Madl (AWS); Weijie Xu (Amazon)*; Olivia Choudhury (Amazon); Matthew Howard (AWS)	</em>
									</li>

									<li><font color="#f56a6a">Differentially Private Synthetic Data via Zeroth-order Optimization</font><br>
									<em>Jingwu Tang (Peking University); Terrance Liu (Carnegie Mellon University); Giuseppe Vietri (University of Minnesota)*; Steven Wu (Carnegie Mellon University)	</em>
									</li>

									<li><font color="#f56a6a">How Do Input Attributes Impact the Privacy Loss in Differential Privacy?</font><br>
									<em>Tamara T. Mueller (Technical University Munich)*; Stefan Kolek (Ludwig Maximilian University of Munich); Friederike Jungmann (Technical University Munich); Alexander Ziller (Technische Universität München); Dmitrii Usynin (Imperial College London); Moritz Knolle (Technische Universität München); Daniel Rueckert (Technische Universität München); Georgios Kaissis (Technische Universität München)	</em>
									</li>

									<li><font color="#f56a6a">Error Maximizing Anti-Sample Generation for Fast Machine Unlearning</font><br>
									<em>Ayush K Tarun (BITS Pilani); Vikram Singh Chundawat (Birla Institute of Technology and Science, Pilani, Pilani Campus); Murari Mandal (Kalinga Institute of Industrial Technology (KIIT) Bhubaneswar)*; Mohan Kankanhalli (National University of Singapore,)	</em>
									</li>

									<li><font color="#f56a6a">Enhancing Privacy Preservation in Federated Learning via Learning Rate Perturbation</font><br>
									<em>Guangnian Wan (Beijing University of Posts and Telecommunications)*; Jie Xu (Beijing University of Posts and Telecommunications); Jun Yang (Beijing University of Posts and Telecommunications); Ru Yan (China Mobile Research Institute); Haitao Du (China Mobile Research Institute); Baojiang Cui (Beijing University of Posts and Telecommunications)	</em>
									</li>

									<li><font color="#f56a6a">Black-Box Audits for Group Distribution Shifts</font><br>
									<em>Marc Juarez (University of Edinburgh)*; Samuel Yeom (Carnegie Mellon University); Matt Fredrikson (Carnegie Mellon University)	</em>
									</li>

									<li><font color="#f56a6a">Data price and quantity decisions for differentially private federated learning in industrial IoT</font><br>
									<em>Haijun Wang (Zhejiang Lab); Bingjie Lu (Zhejiang Lab); Chongning Na (Zhejiang Lab)*	</em>
									</li>

									<li><font color="#f56a6a">On Achieving Privacy-Preserving State-of-the-Art Edge Intelligence</font><br>
									<em>Daphnee N Chabal (University of Amsterdam)*; Dolly Sapra (University of Amsterdam); Zoltan Mann (University of Amsterdam)	</em>
									</li>


									<li><font color="#f56a6a">On the adaptive sensitivity of differentially private machine learning</font><br>
									<em>Filippo Galli (Scuola Normale Superiore)*; Sayan Biswas (INRIA, Ecole Polytechnique); Kangsoo Jung (Inria); Catuscia Palamidessi (Laboratoire d'informatique de l'École polytechnique); Tommaso Cucinotta (Scuola di Studi Superiori Sant'Anna)	</em>
									</li>

									<li><font color="#f56a6a">In-Context Learning as a Simple Baseline for Private Machine Learning</font><br>
									<em>Simran Arora (Stanford University)*; Christopher Re (Stanford University)	</em>
									</li>

									<li><font color="#f56a6a">Privacy evaluation of fairness-enhancing pre-processing techniques</font><br>
									<em>Jean-Christophe Taillandier (Université de Montréal); Sébastien Gambs (UQAM)*	</em>
									</li>

									<li><font color="#f56a6a">Does Differential Privacy Impact Bias in Pretrained NLP Models?</font><br>
									<em>Md Khairul Islam (University of Virginia)*; Andrew J Wang (University of Virginia); Jieyu Zhao (UMD); Yangfeng Ji (University of Virginia); Tianhao Wang (University of Virginia)	</em>
									</li>

									<li><font color="#f56a6a">STONE:When Split meets Transfer for One Shot Learning</font><br>
									<em>Akshat Agrawal (BITS Pilani, Hyderabad)*; Anirudh Kasturi (BITS Pilani, Hyderabad); Chittaranjan Hota (BITS-Pilani, Hyderabad)	</em>
									</li>

									<li><font color="#f56a6a">Guaranteed Confidence Sets for Differentially Private Convex Optimization</font><br>
									<em>Krishnamurthy Dvijotham (Google Research)*; Abhradeep Thakurta (Google)	</em>
									</li>

									<li><font color="#f56a6a">Fairly Private: Investigating The Fairness of Visual Privacy Preservation Algorithms</font><br>
									<em>Sophie Noiret (Vienna University of Technology)*; Siddharth Ravi (University of Alicante); Martin Kampel (Vienna University of Technology, Computer Vision Lab); Francisco Florez-Revuelta (University of Alicante)	</em>
									</li>

									<li><font color="#f56a6a">Rényi Differentially Private Bandits</font><br>
									<em>Achraf Azize (Inria)*; Debabrota Basu (Inria)	</em>
									</li>

									<li><font color="#f56a6a">Toward Compliance Implications and Security Objectives: A Qualitative Study</font><br>
									<em>Dmitry Prokhorenkov (TUM)*	</em>
									</li>

									<li><font color="#f56a6a">Local Differential Privacy for Sequential Decision Making in a Changing Environment</font><br>
									<em>Pratik Gajane (Eindhoven University of Technology)*	</em>
									</li>
								</ul>


							<header class="major" id="tutorials">
								<h3>Tutorial</h3>
							</header>
							<h4 id="salil"> 
							<strong>Using and Contributing to the OpenDP Library</strong>
							<!-- <a href="#" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a> -->
							<!-- <a href="#" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a> -->
							</h4>
							by <a href="https://www.linkedin.com/in/michael-shoemate-17934b98/">Mike Shoemate</a> (Harvard) and 
							<a href="https://salil.seas.harvard.edu">Salil Vadhan</a> (Harvard).
								<p>
							<strong>Abstract</strong>: <br> 
							The OpenDP Project is a community effort to build trustworthy, open-source software tools for analysis of private data.  The core of the OpenDP software is the OpenDP Library, which is a modular collection of statistical algorithms that adhere to the definition of differential privacy. It can be used to build applications of privacy-preserving computations, using a number of different models of privacy. OpenDP is implemented in Rust, with bindings for easy use from Python.  The architecture of the OpenDP Library is based on a flexible framework for expressing privacy-aware computations, coming from the paper A Programming Framework for OpenDP (Gaboardi, Hay, Vadhan 2020).
							<span class="brmed"></span> 
							In this tutorial, we will give a conceptual overview of the OpenDP programming framework.  We will then demonstrate common library APIs, and then show how you may incorporate your own differentially private methods into the library through Python and thereby enable their wider use by the OpenDP community.  We will also show how community-vetted proofs of the privacy properties of the OpenDP components are integrated into the library’s documentation and contribution process. Finally, we will outline OpenDP’s roadmap for the future, and highlight ways in which you can engage.
							</p>
							
							<header class="major" id="invited_talks">
								<h3>Invited Talks</h3>
							</header>
							<h4 id="jon"> 
								<strong> Firm Foundations for Private Machine Learning and Statistics</strong>
							</h4>
							by <a href="https://jonathan-ullman.github.io">Jonathan Ullman</a> (Northeastern University)
							<p>
							<strong>Abstract</strong>: <br>
							In this talk I will describe a work on the foundations of differentially private statistical inference.  A theme of the talk will be how new deployments are forcing us to revisit foundational questions about differential privacy and how studying these questions can inform new deployments.
							</p>
							<p>
							<strong>Bio</strong>: <br>
							Jonathan Ullman is an Associate Professor in the Khoury College of Computer Sciences at Northeastern University.  His research centers on privacy for machine learning and statistics, and its surprising connections to topics like statistical validity, robustness, cryptography, and fairness.  He has been recognized with an NSF CAREER award and the Ruth and Joel Spira Outstanding Teacher Award.
							<!-- <span class="brmed"></span>  -->
							</p>

							<h4 id="borja"> 
								<strong>Privacy in Image Classification Models: Informed Attacks and Practical Defenses</strong>
							</h4>
							by <a href="https://borjaballe.github.io">Borja Balle</a> (DeepMind)
							<p>
							<strong>Abstract</strong>: <br>
							In this talk I will discuss two recent works on privacy attacks and differentially private training for image classification models. On the attacks front I will describe a learning-based method capable of extracting complete training images from standard image classification models. Then I will present some recent advances in private training for large image classification models that achieved state-of-the-art results on challenging benchmarks like CIFAR-10 and ImageNet.
							</p>
							<p>
							<strong>Bio</strong>: <br>
							Borja Balle is a Staff Research Scientist at DeepMind. His current research focuses on privacy-preserving training and privacy auditing for large-scale machine learning systems. He obtained his PhD from Universitat Politècnica de Catalunya in 2013, and then held positions as post-doctoral fellow at McGill University (2013-2015), lecturer at Lancaster University (2015-2017) and machine learning scientist at Amazon Research Cambridge (2017-2019).
							<!-- <span class="brmed"></span>  -->
							</p>


							<h4 id="kobbi"> 
								<strong>Title TBA</strong>
							</h4>
							by <a href="https://people.cs.georgetown.edu/~kobbi/">Kobbi Nissim</a> (Georgetown University)
							<p>
							<strong>Abstract</strong>: <br>
							TBA
							</p>
							<p>
							<strong>Bio</strong>: <br>
							TBA
							<!-- <span class="brmed"></span>  -->
							</p>

							<h4 id="christine"> 
								<strong>Title TBA</strong>
							</h4>
							by <a href="https://knexusresearch.com/team_members/dr-christine-task/">Christine Task</a> (Knexus Coropration)
							<p>
							<strong>Abstract</strong>: <br>
							TBA
							</p>
							<p>
							<strong>Bio</strong>: <br>
							TBA
							<!-- <span class="brmed"></span>  -->
							</p>
							
					
							<header class="major" id="panel">
								<h2>PPAI-22 Panel:</h2>
								<h3>Differential Privacy in real-world deployments: Where are we and what are we missing?</h3>
							</header>
							
							<h3>Panelists</h3>

 							<div class="row">
								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://users.cs.duke.edu/~ashwin/"><img class="center" src="images/ashwin.png" alt=""/></a></span>
									<div class="content"><p class="name">Ashwin Machanavajjhala</p>Duke University and Tumult Labs<br><br>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://gfanti.github.io/website/"><img class="center" src="images/giulia.jpeg" alt=""/></a></span>
									<div class="content"><p class="name">Giulia Fanti</p>Carnegie Mellon University<br><br>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://www.census.gov/newsroom/bios/michael-b-hawes.html"><img class="center" src="images/michael_h.jpeg" alt=""/></a></span>
									<div class="content"><p class="name">Michael B. Hawes</p>U.S. Census Bureau<br><br>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://research.google/people/106916/"><img class="center" src="images/bryantgipson.jpeg" alt=""/></a></span>
									<div class="content"><p class="name">Bryant Gibson</p>Google<br><br>
									</div>
								</div>

						<header class="major" id="invited">
							<h2>Invited Speakers</h2>
						</header>

						<div class="row">
							<div class="col-4 col-12-medium">
								<span class="image left"><a href="https://jonathan-ullman.github.io/"><img class="center" src="images/jon-miriam.jpg" alt=""/></a></span>
								<div class="content"><p class="name">Jonathan Ullman</p>Northeastern University<br><br>
									<p><a href="#jon">Talk details</a></p>
								</div>
							</div>

							<div class="col-4 col-12-medium">
								<span class="image left"><a href="https://people.cs.georgetown.edu/~kobbi/"><img class="center" src="images/Kobbi-Nissim.png" alt=""/></a></span>
								<div class="content"><p class="name">Kobbi Nissim</p>Georgetown University<br><br>
									<p><a href="#kobbi">Talk details</a></p>
								</div>
							</div>

							<div class="col-4 col-12-medium">
								<span class="image left"><a href="https://borjaballe.github.io/"><img class="center" src="images/borja.jpg" alt=""/></a></span>
								<div class="content"><p class="name">Borja Balle</p>DeepMind<br><br>
									<p><a href="#borja">Talk details</a></p>
								</div>
							</div>

							<div class="col-4 col-12-medium">
								<span class="image left"><a href="https://knexusresearch.com/team_members/dr-christine-task/"><img class="center" src="images/Christine_Task.jpg" alt=""/></a></span>
								<div class="content"><p class="name">Christine Task</p>Knexus Coropration<br><br>
									<p><a href="#christine">Talk details</a></p>
								</div>
							</div>

							<div class="col-4 col-12-medium">
								<span class="image left"><a href="https://salil.seas.harvard.edu/"><img class="center" src="images/salil.jpeg" alt=""/></a></span>
								<div class="content"><p class="name">Salil Vadhan</p>Harvard<br><br>
									<p><a href="#salil">Talk details</a></p>
								</div>
							</div>

						</div>
						</section>



						<section>

							<header class="major" id="sponsors">
								<h2>Sponsors</h2>
							</header>
							<div class="row">
								<div class="col-4 col-12-medium">
								<img class="center" src="images/google-logo.png "alt="Google" height="60"><br>
								Gold Sponsor
								</div>
								<div class="col-4 col-12-medium">
								<img class="center" src="images/PET.png "alt="Google" height="60"><br>
								Gold Sponsor
								</div>
							</div>
						<br><br><br>


						<header class="major" id="code">
							<h2>Code of Conduct</h2>
							</header>
							PPAI 2023 is committed to providing an atmosphere that encourages freedom of expression and exchange of ideas. It is the policy of PPAI 2023 that all participants will enjoy a welcoming environment free from unlawful discrimination, harassment, and retaliation.
							<br><br>
							Harassment will not be tolerated in any form, including but not limited to harassment based on gender, gender identity and expression, sexual orientation, disability, physical appearance, race, age, religion or any other status. Harassment includes the use of abusive, offensive or degrading language, intimidation, stalking, harassing photography or recording, inappropriate physical contact, sexual imagery and unwelcome sexual advances. Participants asked to stop any harassing behavior are expected to comply immediately.
							<br><br>
							Violations should be reported to the <a href="#contact">workshop chairs</a>. All reports will be treated confidentially. The conference committee will deal with each case separately. Sanctions include, but are not limited to, exclusion from the workshop, removal of material from the online record of the conference, and  referral to the violator’s university or employer. 
							All PPAI 2023 attendees are expected to comply with these standards of behavior.
						<br><br><br>
					</section>

						<section>
							<header class="major" id="pc">
								<h2>Program Committee</h2>
							</header>

							<ul>
							<li>Abra	Ganz			(University of Amsterdam)</li>
							<li>Ajinkya	Mulay			(Purdue University)</li>
							<li>Akshat	Agrawal			(BITS Pilani, Hyderabad)</li>
							<li>Amrita	Roy Chowdhury	(University of Wisconsin-Madison)</li>
							<li>Anderson	de Oliveira	(SAP)</li>
							<li>Andrei	Paleyes			(University of Cambridge)</li>
							<li>Antti	Honkela			(University of Helsinki)</li>
							<li>Aurélien	Bellet		(INRIA)</li>
							<li>Aws	Albarghouthi		(University of Wisconsin-Madison)</li>
							<li>Ayush	Tarun			(BITS Pilani)</li>
							<li>Borja	Balle			(DeepMind)</li>
							<li>Chittaranjan	Hota	(BITS-Pilani, Hyderabad)</li>
							<li>Chongning	Na			(Zhejiang Lab)</li>
							<li>Christine	Task		(Knexus Research)</li>
							<li>Cuong	Tran			(Syracuse University)</li>
							<li>Damien	Desfontaines	(Tumult Labs)</li>
							<li>Daphnee	Chabal			(University of Amsterdam)</li>
							<li>Di	Wang				(KAUST)</li>
							<li>Dmitrii	Usynin			(Imperial College London)</li>
							<li>Dolly	Sapra			(University of Amsterdam)</li>
							<li>Edward	Raff			(Booz Allen Hamilton)</li>
							<li>Fatemeh	Mireshghallah	(University of California, San Diego)</li>
							<li>Filippo	Galli			(Scuola Normale Superiore)</li>
							<li>Haijun	Wang			(Zhejiang Lab)</li>
							<li>Héber	H. Arcolezi		(Inria and École Polytechnique (IPP))</li>
							<li>Ivan	Habernal		(Technical University of Darmstadt)</li>
							<li>Jan	Ramon				(INRIA)</li>
							<li>Jianfeng	Chi			(University of Virginia)</li>
							<li>Jiankai	Sun				(ByteDance)</li>
							<li>Jiayuan	Ye				(National University of SIngapore)</li>
							<li>Jingwu	Tang			(Peking University)</li>
							<li>Jonathan	Passerat-Palmbach	(Imperial College London / ConsenSys Health)</li>
							<li>Julien	Ferry			(LAAS-CNRS)</li>
							<li>Kangsoo	Jung			(Inria)</li>
							<li>Keyu	Zhu				(Georgia Tech)</li>
							<li>krystal	maughan			(University of Vermont)</li>
							<li>M. Hadi	Amini			(International University)</li>
							<li>Marc	Juarez			(University of Edinburgh)</li>
							<li>Marco	Gaboradi		(Boston University)</li>
							<li>Marco	Romanelli		(NYU Tandon School of Engineering)</li>
							<li>Martin	Kampel			(Vienna University of Technology )</li>
							<li>Michael	Hay				(Colgate University & Tumult Labs)</li>
							<li>Mohammad Mahdi	Khalili	(University of Delaware	)</li>
							<li>Navid	Kagalwalla		(Carnegie Mellon University)</li>
							<li>Olukayode	Akanni		(Near East University)</li>
							<li>Pasin	Manurangsi		(Google)</li>
							<li>Pratik	Karmakar		(RKMVERI)</li>
							<li>Rakshit	Naidu			(Carnegie Mellon University)</li>
							<li>Ranya	Aloufi			(Imperial College)</li>
							<li>Saeyoung	Rho			(Columbia University)</li>
							<li>Sahib	Singh			(OpenMined; Ford R&A)</li>
							<li>Santiago	Zanella-Beguelin		(Microsoft Research)</li>
							<li>Sayan	Biswas			(INRIA, Ecole Polytechnique)</li>
							<li>Sébastien	Gambs		(UQAM)</li>
							<li>Seng Pei	Liew		(LINE Corporation)</li>
							<li>Shangyu	Xie				(Illinois Institute of Technology)</li>
							<li>Simran	Arora			(Stanford University)</li>
							<li>Sung Whan	Yoon		(Ulsan National Institute of Science and Technology)</li>
							<li>Terrence W.K.	Mak		(Georgia Institute of Technology)</li>
							<li>Tianhao	Wang			(University of Virginia)</li>
							<li>Tsubasa	Takahashi		(LINE Corporation)</li>
							<li>Vikram	Chundawat		(Birla Institute of Technology and Science)</li>
							<li>Virat	Shejwalkar		(UMass Amherst)</li>
							<li>Xiaoting	Zhao		(Etsy)</li>
							<li>Yuanshun	Yao			(ByteDance)</li>
							<li>Yuliia	Lut				(Columbia University)</li>
							<li>Yunwen	Lei				(University of Birmingham)</li>
							<li>Yuya	Sasaki			(Osaka University)</li>
 							</ul>

 							<br>
							<header class="major" id="chairs">
								<h2>Workshop Chairs</h2>
							</header>

							<div class="row">
								<!-- <article> -->
								<div class="col-4 col-12-medium">
									<span class="image left">
										<a href="https://www.nandofioretto.com"><img class="center" src="images/Nando.png" alt=""/></a>
									</span>
									<div class="content">
										<p class="name">Ferdinando Fioretto</p>
										Syracuse University
										<br><br>
										<p>
											<a href="mailto:ffiorett@syr.edu">ffiorett@syr.edu</a>
										</p>
									</div>
								</div>
								<!-- <article> -->
								<div class="col-4 col-12-medium">
									<span class="image left"><a href="http://www.lix.polytechnique.fr/~catuscia/">
										<img class="center" src="images/catuscia.jpg" alt=""/></a></span>
									<div class="content">
										<p class="name">Catuscia Palamidessi</p>
										Inria, Ecole Polytechnique
										<br><br>
										<p>
											<a href="mailto:catuscia@lix.polytechnique.fr">catuscia@lix.polytechnique.fr</a>
										</p>
									</div>
								</div>


								<!-- <article> -->
								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://sites.gatech.edu/pascal-van-hentenryck/"><img class="center" src="images/Pascal.png" alt=""/></a></span>
									<div class="content">
										<p class="name">Pascal Van Hentenryck</p>
										Georgia Institute of Technology
										<br><br>
										<p>
											<a href="mailto:pvh@isye.gatech.edu">pvh@isye.gatech.edu</a>
										</p>
									</div>
								</div>
								<!-- </article> -->
							</div>
						</section>
				</div>
			</div>

		<!-- Sidebar -->
			<div id="sidebar">
				<div class="inner">
					<!-- Menu -->
						<nav id="menu">
							<header class="major">
								<h2>PPAI23</h2>
							</header>
							<ul>
								<li><a href="#scope">Scope</a></li>
								<li><a href="#dates">Important Dates</a></li>
								<li><a href="#submission">Submission</a></li>
								<li>
									<span class="opener">Program</span>
									<ul>
									<li><a href="#program">Schedule</a></li>
									<li><a href="#tutorials">Tutorials</a></li>
									<li><a href="#invited_talks">Invited Talks</a></li>
									<li><a href="#panel">Panel</a></li>
									</ul>
								</li>
                                <li><a href="#scholarship">Scholarships</a></li>
                                <li><a href="#registration">Registration</a></li>
								<li><a href="#accepted_papers">Accepted Papers</a></li>
								<li><a href="#invited">Invited Speakers</a></li> 
 								<li><a href="#pc">Program Committee</a></li>
								<li><a href="#chairs">Workshop Chairs</a></li>
								<li>
									<span class="opener">Previous Editions</span>
									<ul>
									<li><a href="https://aaai-ppai22.github.io/">PPAI 2022</a></li>
									<li><a href="https://ppai21.github.io/">PPAI 2021</a></li>
									<li><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/">PPAI 2020</a></li>
									</ul>
								</li>

							</ul>
						</nav>

					<!-- Section -->
						<section>
							<header class="major">
								<h2>Contacts</h2>
							</header>
<!-- 									<p>.</p> -->	
						<ul class="contact">
							<li class="icon solid fa-envelope"><a href="mailto:ffiorett@syr.edu,">Email chairs</a></li>
							<!-- <li class="icon brands fa-twitter"><a href="https://twitter.com/PPAI211">Twitter</a></li> -->
						</ul>
						</section>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">Website template from: <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

					</div>
				</div>

		</div>

	<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

	</body>
</html>
