<!DOCTYPE HTML>
<html>
	<head>
		<title>Third AAAI Workshop on Privacy-Preserving Artificial Intelligence</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="keywords" content="PPAI,PPAI22,PPAI2022,PPAI 22,PPAI 2022,AAAI,AAAI22,AAAI 2022,Privacy Preserving AI,Privacy Preserving Artificial Intelligence,AI, Differential Privacy,Privacy,Preserving,Artificial,Intelligence"/>
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">
				<!-- Main -->
				<div id="main">
					<div class="inner">
						<!-- Banner -->
						<section id="banner">
							<div class="content">
								<header>
									<h1>The Third AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-22)</h1>
									<p>TBA February, 2022</p>
								</header>
							</div>
							<span class="center">
								<img class="center" src="images/logo-ppai.png" alt=""/>
							<!--<img class="center" src="images/aaai.png" alt="" width="128"/> -->									</span>
						</section>

						<!-- Section -->
						<section>
							<header class="major" id="scope">
								<h2>Scope and Topics</h2>
							</header>
							<p>
							The availability of massive amounts of data, coupled with high-performance cloud computing 
							platforms, has driven significant progress in artificial intelligence and, in particular, 
							machine learning and optimization. It has profoundly impacted several areas, including computer 
							vision, natural language processing, and transportation. However, the use of rich data sets 
							also raises significant privacy concerns: They often reveal personal sensitive information 
							that can be exploited, without the knowledge and/or consent of the involved individuals, for 
							various purposes including monitoring, discrimination, and illegal activities. 
							<br>
							The second AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-21) held at the 
							<a href="https://aaai.org/Conferences/AAAI-22/">Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)</a> 
							builds on the success of previous years 
							<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20/">AAAI PPAI-20</a> and 
							<a href="https://ppai21.github.io/">AAAI PPAI-21</a> 
							to provide a platform for researchers, AI practitioners, and policymakers to discuss technical 
							and societal issues and present solutions related to privacy in AI applications. 
							The workshop will focus on both the theoretical and practical challenges related to the design 
							of privacy-preserving AI systems and algorithms and will have strong multidisciplinary 
							components, including soliciting contributions about policy, legal issues, and societal 
							impact of privacy in AI. 
							</p>
							PPAI-21 will place particular emphasis on: 
							<ol>
								<li>Algorithmic approaches to protect data privacy in the context of learning, 
									optimization, and decision making that raise fundamental challenges for 
								existing technologies.</li> 
								<li>Privacy challenges created by the governments and tech industry response to 
								the Covid-19 outbreak.</li> 
								<li>Social issues related to tracking, tracing, and surveillance programs.</li> 
								<li>Algorithms and frameworks to release privacy-preserving benchmarks and data sets.</li> 
							</ol>

							<h3>Topics</h3>
							The workshop organizers invite paper submissions on the following (and related) topics:
							<ul>
								<li>Applications of privacy-preserving AI systems</li>
								<li>Attacks on data privacy</li>
								<li>Differential privacy: theory and applications</li>
								<li>Distributed privacy-preserving algorithms</li>
								<li>Human rights and privacy</li>
								<li>Privacy issues related to the Covid-19 outbreak </li>
								<li>Privacy policies and legal issues </li>
								<li>Privacy preserving optimization and machine learning </li>
								<li>Privacy preserving test cases and benchmarks</li>
								<li>Surveillance and societal issues </li>
							</ul>
							<p>
								Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and data sets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples. 
							</p>

							<h3>Format</h3> <p> The workshop will be a one-day 
							meeting.  It will be dedicated to the workshop technical
							content about  privacy-preserving AI. The workshop will include
							a number of (possibly parallel) technical  sessions, a virtual
							poster session where presenters can discuss their work, with
							the aim of  further fostering collaborations, multiple invited
							speakers covering crucial challenges for  the field of
							privacy-preserving AI applications, including policy and
							societal impacts, a  number of tutorial talks, and will
							conclude with a panel discussion.  </p>

<!-- 							<h3>Attendance</h3>
							Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
 -->
 							</section>


						<section>
							<header class="major" id="dates">
								<h2>Important Dates</h2>
							</header>
							<ul>
							<li><strong>November 16, 2020</strong> – Submission Deadline <font color="#f56a6a">[Extended]</font></li>
							<li><strong>December 7, 2020</strong>  – AAAI Fast Track Submission Deadline <font color="#f56a6a">[New]</font></li>
							<li><strong>January 7, 2021</strong> – Acceptance Notification <font color="#f56a6a">[Updated]</font></li>
							<li><strong>February 8 and 9, 2020</strong> – Workshop Date </li>
							</ul>
						</section>

						<section>
							<header class="major" id="submission">
								<h2>Submission Information</h2>
							</header>

							<p>
							Submission URL:  <a href="https://cmt3.research.microsoft.com/PPAI2021">https://cmt3.research.microsoft.com/PPAI2021</a>
							</p>

							<h3>Submission Types</h3>
							<ul>
								<li><strong>Technical Papers</strong>: 
								Full-length research papers of up to 7 pages (excluding references and appendices) 
								detailing high quality work in progress or work that could potentially be published at 
								a major conference. 
								</li>
								<li><strong>Short Papers</strong>: 
								Position or short papers of up to 4 pages (excluding references and appendices) that 
								describe initial work or the release of privacy-preserving benchmarks and datasets on the 
								topics of interest. 
								</li>
							</ul>

							<h3>Submission Tracks</h3>
							<ul>
								<li><strong>Technical Track</strong>:
									 This track is dedicated to the privacy-preserving AI technical content. It welcomes 
									 research contributions centered around the topics described above.
								</li>
								<li><strong>Privacy Challenges and Social Issues Track</strong>:
									This track is dedicated to discussion of privacy challenges, particularly those risen 
									by the Covid-19 pandemic tracing and tracking policy programs. 
									It welcomes both technical contributions and position papers. 
								</li>
							</ul>

							<h4><font color="#f56a6a">[New]</font> AAAI Fast Track (Rejected AAAI papers)</h4>
							<p>
							Rejected AAAI papers with *average* scores of at least 4.5 may be asubmitted directly to PPAI 
							along with previous reviews. These submissions may go through a light review process or 
							accepted if the provided reviews are judged to meet the workshop standard. 
							</p>

							<p>	
							All papers must be submitted in PDF format, using the <a href="https://www.aaai.org/Publications/Templates/AuthorKit21.zip">AAAI-21 author kit</a>. 
							Submissions should include the name(s), affiliations, and email addresses of all authors. 
							<br>
							Submissions will be refereed on the basis of technical quality, novelty, significance, and 
							clarity. Each submission will be thoroughly reviewed by at least two program committee members.
							<br>
							Submissions of papers rejected from the AAAI 2021 technical program are welcomed. 
							<!-- Papers will be selected for oral and/or poster presentation at the workshop.  -->
							</p>

							<p>
							For questions about the submission process, contact the workshop <a href="#contact">chairs</a>.
							</p>
						</section>

						<section>
							<header class="major" id="program">
								<h2>Program</h2>
							</header>

							All times are in Eastern Standard Time (UTC-5).</br><br>

							<strong>Invited talks, Tutorials, and Panel discussion</strong>: Will be live streamed (recording available).
							</br>
							<strong>Spotlights and Poster Talks</strong>: Are pre-recorded and accessible at any time (click on the play button next to the associated paper). 
							There will be additional Q&A and discussion at the poster sessions.
							<br>
							<strong>Poster sessions</strong>: are hosted on <a href="https://discord.gg/dPRvVuhKuW">Discord</a>. See <a href="#poster-instructions">instructions below</a>.
							<br><br>

							<h4>PPAI Day 1 - February 8, 2021</h4>
							<div class="table-wrapper">
								<table>
									<thead>
										<tr>
											<th colspan="1">Time</th>
											<th>Talk / Presenter </th>
											<th></th>
										</tr>
									</thead>
									<tbody>
										<tr><td>08:50</td>	<td>Introductory remarks</td> <td></td>		</tr>
										<tr><td>09:00</td>	<td><a href="#john">Invited Talk</a> by <em>John M. Abowd</em></td> 	<td style="text-align: center;"><a href="https://www.youtube.com/watch?v=cmgMTq6NXKI" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr height="8px">
										<td colspan="3">Session chair: <em>Xi He</em></td></tr>
										<tr><td>09:45</td>	<td><a href="#sp1">Spotlight Talk</a>: On the Privacy-Utility Tradeoff in Peer-Review Data Analysis</td>							<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/41-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>10:00</td>	<td><a href="#sp2">Spotlight Talk</a>: Leveraging Public Data in Practical Private Query Release: A Case Study with ACS Data</td>	<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/26-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>10:30</td>	<td><a href="#aswin">Invited Talk</a> by <em>Aswin Machanavajjhala</em></td> <td style="text-align: center;"><a href="https://www.youtube.com/watch?v=gwaIA-V-rt8" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr><td>11:15</td>  <td colspan="2">Break</td></tr>
										<tr><td>11:20</td>	<td><a href="#audra">Tutorial</a>: A tutorial on privacy amplification by subsampling, diffusion and shuffling, by <em>Audra McMillan</em></td> <td style="text-align: center;"><a href="https://www.youtube.com/watch?v=lJzP3uggLpY" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr><td>12:50</td>  <td colspan="2">Break</td></tr>
										<tr height="8px"><td colspan="3">Session chair: <em>Marco Romanelli</em></td></tr>
										<tr><td>13:30</td>	<td><a href="#sp3">Spotlight Talk</a>: Efficient CNN Building Blocks for Encrypted Data</td>				<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/30-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>13:45</td>	<td><a href="#sp4">Spotlight Talk</a>: Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach</td>				<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/17-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>14:00</td>	<td><a href="#sp5">Spotlight Talk</a>: A variational approach to privacy and fairness</td>				<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/36-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>14:15</td>	<td><a href="#steven">Invited Talk</a> by <em>Steven Wu</em></td>			<td style="text-align: center;"><a href="https://www.youtube.com/watch?v=1CGOJWiWW0M" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr><td>15:00</td>	<td>Poster Session 1</td> <td style="text-align: center; white-space: nowrap;"><a href="https://discord.gg/dPRvVuhKuW">join (on Discord)</a></td>		</tr>
										<tr><td>17:00</td> <td colspan="2">End of Workshop (day 1)</td></tr>
										<tr><td colspan="3" style="background-color: white;"> <br><h4>PPAI Day 2 - February 9, 2021</h4> </td></tr>
									</tbody>
									<thead>
										<tr>
											<th colspan="1">Time</th>
											<th>Talk / Presenter </th>
											<th></th>
										</tr>
									</thead>
									<tbody>
										<tr><td>09:00</td>	<td><a href="#reza">Invited Talk</a> by <em>Reza Shokri</em></td> 	<td style="text-align: center;"><a href="https://youtu.be/e7aUGNKg4vA" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a></td>		</tr>
										<tr height="8px"><td colspan="3">Session chair: <em>TBA</em></td></tr>
										<tr><td>09:45</td>	<td><a href="#sp6">Spotlight Talk</a>: Coded Machine Unlearning</td>	<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/20-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>10:00</td>	<td><a href="#sp7">Spotlight Talk</a>: DART: Data Addition and Removal Trees</td>	<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/37-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>10:30</td>	<td><a href="#nicolas">Invited Talk</a> by <em>Nicolas Papernot</em></td> <td style="text-align: center;"><a href="https://www.youtube.com/watch?v=XhgwUl-2w9Q" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr><td>11:15</td>  <td colspan="2">Break</td></tr>
										<tr><td>11:20</td>	<td><a href="#fedlearning">Tutorial</a>: Privacy and Federated Learning: Principles, Techniques and Emerging Frontiers
											 						        by <em>Brendan McMahan, Kallista Bonawitz, and Peter Kairouz</em></td> <td style="text-align: center;"><a href="https://www.youtube.com/watch?v=prQI5OT_wzk" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr><td>12:50</td>  <td colspan="2">Break</td></tr>
										<tr height="8px"><td colspan="3">Session chair: <em>Mark Bun</em></td></tr>
										<tr><td>13:30</td>	<td><a href="#sp8">Spotlight Talk</a>: Reducing ReLU Count for Privacy-Preserving CNNs</td>				<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/8-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>13:45</td>	<td><a href="#sp9">Spotlight Talk</a>: Output Perturbation for General Differentially Private Convex<br> Optimization with Improved Population Loss Bounds, Runtimes and Applications to Private Adversarial Training</td>	<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/15-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>14:00</td>	<td><a href="#sp10">Spotlight Talk</a>: An In-depth Review  of Privacy Concerns Raised by  the COVID-19 Pandemic</td>	<td style="text-align: center;"><a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/34-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a></td>		</tr>
										<tr><td>14:15</td>	<td><a href="#panel">Panel</a>: “Differential Privacy: Implementation, deployment, and receptivity. Where are we and what are we missing?” </td>	<td style="text-align: center;"><a href="https://www.youtube.com/watch?v=GlKB8xwXMSE" target="_blank" style="border-bottom: none"><img src="images/play.png" width="20"></a></td>		</tr>
										<tr><td>15:00</td>	<td>Poster Session 2</td> <td style="text-align: center; white-space: nowrap;"><a href="https://discord.gg/dPRvVuhKuW">join (on Discord)</a></td>		</tr>
										<tr><td>17:00</td>  <td colspan="2">End of Workshop</td></tr>
									</tbody>
								</table>

								<h5 id="poster-instructions">Poster Presentation instructions on Discord</h5>
									Each contributed paper is associated with two channels: 
									<ul>
										<li><strong>Text channel</strong>: Here is where you will find a short video presentation 
											(2 min) and a poster slide associated with each paper.<br>
											You can: 
											1. Visualize the material, and
											2. Leave questions for the authors to respond (outside the poster session time frame). </li>
										<li><strong>Video channel</strong>:
											It is used for Q&A and discussion during the poster session time. 
											When joining a voice channel, remember turn on your mic (and, optionally, your camera).</li>
									</ul>
							</div>



							<header class="major" id="accepted_papers">
								<h3>Accepted Papers</h3>
							</header>

								<h5 id="spotlight">Spotlight Presentations</h5>
								<ul>
									<li id="sp1"><font color="#f56a6a">On the Privacy-Utility Tradeoff in Peer-Review Data Analysis</font> 
										<a href="files/41-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/41-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2006.16385" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
										<br>
										<em>Wenxin Ding (Carnegie Mellon University); Nihar Shah (CMU); Weina Wang (CMU)</em><br>
										<!-- https://arxiv.org/pdf/2006.16385.pdf -->
									</li>
									<li  id="sp2"><font color="#f56a6a">Leveraging Public Data in Practical Private Query Release: A Case Study with ACS Data</font>
										<a href="files/26-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/26-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<br>
										<em>Terrance Liu (Carnegie Mellon University); Giuseppe Vietri (University of Minnesota); Thomas Steinke (Google); Jonathan Ullman (Northeastern University); Steven Wu (Carnegie Mellon University)</em>
									</li>
									<li  id="sp3"><font color="#f56a6a">Efficient CNN Building Blocks for Encrypted Data</font>
										<a href="files/30-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/30-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2102.00319" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>										
										<br>
										<em>Nayna Jain (IIIT Bangalore); 
									        Karthik Nandakumar (Mohamed Bin Zayed University of Artificial Intelligence, UAE);
											Nalini Ratha (SUNY Buffalo); Sharath Pankanti (Microsoft); Uttam Kumar (IIIT Bangalore)</em>
									</li>
									<li  id="sp4"><font color="#f56a6a">Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach</font>
										<a href="files/17-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/17-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2009.12562" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
										<br>
										<em>Cuong Tran (Syracuse University)</em>
									</li>
									<li  id="sp5"><font color="#f56a6a">A variational approach to privacy and fairness</font>
										<a href="files/36-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/36-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2006.06332" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>										
										<br>
										<em>Borja Rodríguez Gálvez (KTH Royal Institute of Technology); Ragnar Thobaben (KTH Royal Institute of Technology); Mikael Skoglund (KTH Royal Institute of Technology)</em>
											<!-- https://arxiv.org/abs/2006.06332 -->
									</li>
									<li id="sp6"><font color="#f56a6a">Coded Machine Unlearning</font>
										<a href="files/20-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/20-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<br>
										<em>Nasser Aldaghri (University of Michigan); Hessam Mahdavifar (University of Michigan); Ahmad Beirami (Facebook, USA)</em>
									</li>
									<li  id="sp7"><font color="#f56a6a">DART: Data Addition and Removal Trees</font>
										<a href="files/37-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/37-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2009.05567" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
										<br>
										<em>Jonathan Brophy (University of Oregon); Daniel Lowd (University of Oregon)</em>
<!-- 										https://arxiv.org/abs/2009.05567 -->
									</li>
									<li id="sp8"><font color="#f56a6a">Reducing ReLU Count for Privacy-Preserving CNNs</font>
										<a href="files/8-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/8-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2101.11835" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
										<br>
										<em>Inbar Helbitz (Tel Aviv University); Shai Avidan (Tel Aviv University)</em>
										<!-- https://arxiv.org/abs/2101.11835 -->
									</li>
									<li  id="sp9"><font color="#f56a6a">Output Perturbation for General Differentially Private Convex Optimization with Improved Population Loss Bounds, Runtimes and Applications to Private Adversarial Training</font>
	 									<a href="files/15-paper.pdf" alt="" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/15-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2102.04704" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
										<br>
										<em>Andrew Lowy (USC); Meisam Razaviyayn (USC)</em>
									</li>
									<li  id="sp10"><font color="#f56a6a">An In-depth Review  of Privacy Concerns Raised by  the COVID-19 Pandemic</font>
										<a href="files/34-paper.pdf" alt="" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
										<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/34-long.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
										<a href="https://arxiv.org/abs/2101.10868" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
										<br>
										<em>Jiaqi Wang (Penn State University)</em>
									</li>
								</ul>

								<h5>Poster Presentations</h5>
								<ul>
									<li><font color="#f56a6a">Differentially Private Random Forests for Regression and Classification</font>
									<a href="files/2-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/2-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Shorya Consul (University of Texas at Austin); Sinead Williamson (UT Austin/CognitiveScale)</em>
								</li>
								<li><font color="#f56a6a">An Analysis Of Protected Health Information Leakage In Deep-Learning Based De-Identification Algorithms</font>
									<a href="files/4-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/4-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2101.12099" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Salman Seyedi (Emory University)</em>
<!-- 									https://arxiv.org/abs/2101.12099 -->
								</li>
								<li><font color="#f56a6a">Dopamine: Differentially Private Secure Federated Learning on Medical Data</font>
									<a href="files/5-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/5-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2101.11693" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Mohammad Malekzadeh (Imperial College London); Burak  Hasircioglu ( Imperial College London); Nitish Mital  (Imperial College London	); Kunal  Katarya (Imperial College London	); Mehmet Emre Ozfatura (Imperial College London); Deniz Gunduz (Imperial College London)</em>
								</li>
									<!-- https://arxiv.org/abs/2101.11693 -->
								<li><font color="#f56a6a">Differential Privacy Meets Maximum-weight Matching</font>
									[paper not available]<!-- <a href="files/7-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a> -->
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/7-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Panayiotis Danassis (École Polytechnique Fédérale de Lausanne); Aleksei Triastcyn (EPFL); Boi Faltings (EPFL)</em>
								</li>
								<li><font color="#f56a6a">Intelligent Frame Selection as a  Privacy-Friendlier Alternative to Face Recognition</font>
									<a href="files/10-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/10-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2101.07529" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Mattijs Baert (Ghent University - IMEC); Sam Leroux (Ghent University - IMEC); Pieter Simoens (Ghent University - imec)</em>
								</li>
									<!-- https://arxiv.org/abs/2101.07529 -->
								<li><font color="#f56a6a">Accuracy and Privacy Evaluations of Collaborative Data Analysis</font>
									<a href="files/12-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/12-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2101.11144" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Akira Imakura (University of Tsukuba); Anna Bogdanova (University of Tsukuba); Takaya Yamazoe (University of Tsukuba); Kazumasa Omote (University of Tsukuba); Tetsuya Sakurai (University of Tsukuba)</em>
								</li>
									<!-- https://arxiv.org/abs/2101.11144 -->
								<li><font color="#f56a6a">Maintaining the Utility of Privacy-Aware Schedules</font>
									[paper not available]
									<!-- <a href="files/14-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a> -->
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/14-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Arik Senderovich (University of Toronto); Ali Kaan  Tutak (Humboldt University of Berlin); Christopher Beck (University of Toronto); Stephan Fahrenkrog-Petersen (Humboldt University of Berlin); Matthias Weidlich (Humboldt-Universität zu Berlin)</em>
								</li>
								<li><font color="#f56a6a">A Study of F0 Modification for X-Vector Based Speech Pseudo-Anonymization Across Gender</font>
									<a href="files/16-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/16-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2101.08478" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Champion Pierre (INRIA); Denis Jouvet (INRIA); Anthony Larcher (Universitad du Mans - LIUM)</em>
								</li>
									<!-- https://arxiv.org/abs/2101.08478 -->
								<li><font color="#f56a6a">Private Emotion Recognition with Secure Multiparty Computation</font>
									<a href="files/18-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/18-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2007.00253" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Kyle J Bittner (University of Washington Tacoma); Rafael Dowsley (Monash University); Martine De Cock (University of Washington Tacoma)</em>
								</li>
									<!-- https://arxiv.org/abs/2007.00253 -->
								<li><font color="#f56a6a">Optimized Data Sharing with Differential Privacy: A Game-theoretic Approach</font>
									<a href="files/21-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/21-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Nan Wu (Macquarie University and CSIRO's Data61); Farhad Farokhi (The University of Melbourne); David Smith (DATA61, CSIRO); Mohamed Ali Kaafar (Macquarie University and CSIRO-Data61)</em>
								</li>
								<li><font color="#f56a6a">Personalized privacy protection in social networks through adversarial modeling</font>
									<a href="files/27-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/27-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Sachin G Biradar (Amazon.Inc); Elena Zheleva (University of Illinois at Chicago)</em>
								</li>
								<li><font color="#f56a6a">Hybrid Privacy Scheme</font>
									<a href="files/28-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/28-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Yavor Litchev (Lexington High School); Abigail Thomas (Nashua High School South)</em>
								</li>
								<li><font color="#f56a6a">Compressive Differentially-Private Federated Learning Through Universal Vector Quantization</font>
									<a href="files/29-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/29-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Saba Amiri (University of Amsterdam); Adam Belloum (Multiscale Networked Systems (MNS) Research Group, University of Amsterdam, 1098 XH Amsterdam, The Netherlands); Leon Gommans (Air France KLM); Sander  Klous (Vrije Universiteit Amsterdam)</em>
								</li>
								<li><font color="#f56a6a">S++: A Fast and Deployable Secure-Computation Framework for Privacy-Preserving Neural Network Training </font>
									<a href="files/33-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/33-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<a href="https://arxiv.org/abs/2101.12078" alt="ArXiv Link" style="border-bottom: none"><strong>[ArXiv]</strong></a>
									<br>
									<em>Prashanthi Ramachandran (Ashoka University); Shivam Agarwal (Ashoka University); Aastha Shah (Ashoka University); Arup Mondal (Ashoka University); Debayan Gupta (Ashoka University)</em>
								</li>
								<li><font color="#f56a6a">Differentially Private Multi-Agent Constraint Optimization</font>
									[paper not available]
									<a href="files/38-paper.pdf" alt="ArXiv Link" style="border-bottom: none"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle"></a>
									<a href="https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI21/38-short.mp4" alt="Video" style="border-bottom: none"><img src="images/play.png" width="20" style="vertical-align:middle"></a>
									<br>
									<em>Sankarshan Damle (Machine Learning Lab, International Institute of Information Technology, Hyderabad); Aleksei Triastcyn (EPFL); Boi Faltings (EPFL); Sujit  P.  Gujar (Machine Learning Laboratory, International Institute of Information Technology, Hyderabad)</em>
								</li>
								</ul>

							<header class="major" id="tutorials">
								<h3>Tutorials</h3>
							</header>

							<h4 id="fedlearning">
								Privacy and Federated Learning: Principles, Techniques and Emerging Frontiers
								<a href="files/BM_KB_PK-slides.pdf" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a>
								<a href="https://www.youtube.com/watch?v=prQI5OT_wzk" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
							</h4> 
								by 
								<a href="https://research.google/people/author35837/">Brendan McMahan</a> (Google), 
								<a href="https://research.google/people/105175/">Kallista Bonawitz</a> (Google),
								<a href="https://kairouzp.github.io/">Peter Kairouz</a>  (Google)								
								<p>
								<strong>Abstract</strong>: <br>
								Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. Similarly, federated analytics (FA) allows data scientists to generate analytical insight from the combined information in distributed datasets without requiring data centralization. Federated approaches embody the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in federated learning and analytics, this tutorial will provide a gentle introduction to the area. The focus will be on cross-device federated learning, including deep dives on differential privacy and secure computation in the federated setting; federated analytics and cross-silo federated learning will also be discussed.
								</p>

							<h4 id="audra">A tutorial on privacy amplification by subsampling, diffusion and shuffling 
<!-- 								<a href="#" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a>
 -->								<a href="https://www.youtube.com/watch?v=lJzP3uggLpY" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
							</h4>
								by
								<a href="https://audramarymcmillan.wixsite.com/mysite">Audra McMillan</a> (Apple) 
								<p>
								<strong>Abstract</strong>: <br>
								Practical differential privacy deployments require tight privacy accounting. A toolbox of “privacy amplification” techniques has been developed to simplify the privacy analysis of complicated differentially private mechanisms. These techniques can be used to design new differentially private mechanisms, as well as provide tighter privacy guarantees for existing mechanisms. In this tutorial, we will discuss three main privacy amplification techniques; subsampling, diffusion and shuffling. We will discuss the intuition for why each technique amplifies privacy, and where it is useful in practice. Finally, we will use differentially private stochastic gradient descent as an example of how each technique can be used to easily provide a tight, or almost tight, privacy analysis.
								</p>
						



							<header class="major" id="invited_talks">
								<h3>Invited Talks</h3>
							</header>
								<h4 id="john"> 
								Differential Privacy and the 2020 Census in the United States
								<a href="files/JA-slides.pdf" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a>
								<a href="https://www.youtube.com/watch?v=cmgMTq6NXKI" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
							</h4>
								by <a href="https://www.ilr.cornell.edu/people/john-abowd">John M. Abowd</a> (U.S. Census Bureau)
 								<p>
								<strong>Abstract</strong>: <br>
								The talk will focus on the implementation of differential privacy used to protect the data products in the 2020 Census of Population and Housing. I will present a high-level overview of the design used for the majority of the data products, known as the TopDown Algorithm. I will focus on the high-level policy and technical challenges that the U.S. Census Bureau faced during the implementation including the original science embodied in that algorithm, implementation challenges arising from the production constraints, formalizing policies about privacy-loss budgets, communicating the effects of the algorithms on the final data products, and balancing competing data users' interests against the inherent privacy loss associated with detailed data publications.
								</p>
								<!-- John Abowd is the U.S. Census Bureau’s associate director for research and methodology, and chief scientist. He was named to the position in June 2016. The Research and Methodology Directorate leads critical work to modernize our operations and products. He is leading the agency’s efforts to create a differentially private protection system for the 2020 Census and future data products. His long association with the Census Bureau began in 1998 when he joined the team that helped found the longitudinal employer-household dynamics program. In 2008, he led the team that created the world’s first application of a differentially private protection system for the program’s OnTheMap job location tool. Abowd is also the Edmund Ezra Day Professor of economics, statistics, and information science at Cornell University. He is a fellow and past president of the Society of Labor Economists. He is also a fellow of the American Statistical Association and the Econometric Society, as well as an elected member of the International Statistical Institute. He earned his Ph.D. from the University of Chicago and an A.B. from the Department of Economics at the University of Notre Dame. -->

								<h4 id="nicolas">
								Three Flavors of Private Machine Learning
								<a href="files/NP-slides.pdf" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a>
								<a href="https://www.youtube.com/watch?v=XhgwUl-2w9Q" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
								</h4>
								by <a href="https://www.papernot.fr/">Nicolas Papernot</a> (University of Toronto) 
 								<p>
								<strong>Abstract</strong>: <br>
								Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information. To address this problem, algorithms for private machine learning have been proposed. In this talk, we first show that training neural networks with privacy requires rethinking their architectures with the goals of privacy-preserving gradient descent in mind. Second, we explore how private aggregation surfaces the synergies between privacy and generalization in machine learning. Third, we present recent work towards a form of collaborative machine learning that is both privacy-preserving in the sense of differential privacy, and confidentiality-preserving in the sense of the cryptographic community.
								</p>

								<h4 id="ashwin">
								Deploying Differential Privacy for Social Good: Opportunities and Challenges
								<!-- <a href="#" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a> -->
								<a href="https://www.youtube.com/watch?v=gwaIA-V-rt8" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
								</h4>
								by <a href="https://users.cs.duke.edu/~ashwin/">Ashwin Machanavajjhala</a> (Duke University) 
 								<p>
								<strong>Abstract</strong>: <br>
								Several organizations, especially federal statistical agencies, routinely release fine grained statistical data products for social good that are critical for enabling resource allocation, policy and decision making as well as research. Differential privacy, the gold standard privacy technology, has long been motivated by this use case. In this talk, I will describe our recent experiences deploying differential privacy at scale at US federal statistical agencies. I will highlight how the process of deploying DP at these agencies differs from the idealized problem studied in the research literature, and illustrate a few key technical challenges we encountered in these deployments.   
								</p>

								<h4 id="reza">
									Modeling Privacy Erosion: Differential Privacy Dynamics in Machine Learning
<!-- 									<a href="#" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a>
-->									<a href="https://youtu.be/e7aUGNKg4vA" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
 								</h4>
								by <a href="https://www.comp.nus.edu.sg/~reza/">Reza Shokri</a> (National University of Singapore) 
 								<p>
								<strong>Abstract</strong>: <br>
								Machine learning models leak information about their training data. Randomizing gradients during training is a technique to preserve differential privacy, and protect against inference attacks. The general method to compute the differential privacy bound is to use composition theorems: to view the training process as a sequence of differentially-private algorithms, and to compute the composition of their DP bounds.  This results in a loose bound on the privacy loss of the released model, as it accounts for the privacy loss of all training epochs (even if the intermediate parameters are not released).  I will present a novel approach for analyzing the dynamics of privacy loss, throughout the training process, assuming that the internal state of the algorithm (its parameters during training) remains private. This enables computing how privacy loss changes after each training epoch, and the privacy loss at the time of releasing the model. I show that differential privacy bound converges, and it converges to a tight bound.

								</p>

								<h4 id="steven">
									Leveraging Heuristics for Private Synthetic Data Release
									<!-- <a href="#" target="_blank"><img src="images/pdf-icon.png" width="20" style="vertical-align:middle" alt="slides"></a> -->
									<a href="https://www.youtube.com/watch?v=1CGOJWiWW0M" target="_blank"><img src="images/play.png" width="20" style="vertical-align:middle" alt="video recording"></a>
								</h4>
								by <a href="https://zstevenwu.com">Steven Wu</a> (Carnegie Mellon University) 
 								<p>
								<strong>Abstract</strong>: <br>
								This talk will focus on differentially private synthetic data---a privatized version of the dataset that consists of fake data records and that approximates the real dataset on important statistical properties of interest. I will present our recent results on private synthetic data that leverage practical optimization heuristics to circumvent the computational bottleneck in existing work. Our techniques are motivated by a modular, game-theoretic framework, which can flexibly work with methods such as integer program solvers and deep generative models.
								</p>

 
							<header class="major" id="panel">
								<h3>PPAI-21 Panel</h3>
							</header>
							<h4>Differential Privacy: Implementation, deployment, and receptivity. Where are we and what are we missing?</h4>

							<strong>Panelists</strong>:<br>
							<ul>
								<li><a href="https://sites.gatech.edu/rachel-cummings/">Rachel Cummings</a> (Columbia University)</li> <!-- <racheladcummings@gmail.com> -->
								<li><a href="https://www.tonic.ai/about">Ander Steele</a> (Tonic.ai)</li> <!-- <adam@tonic.ai> -->
								<li><a href="https://viterbi.usc.edu/directory/faculty/Korolova/Aleksandra">Aleksandra Korolova</a> (University of Southern California)</li> <!-- <korolova@usc.edu> -->
								<li><a href="https://knexusresearch.com/team_members/dr-christine-task/">Christine Task</a> (Knexus Research)</li> <!-- <christine.task@knexusresearch.com> -->
							</ul>
						</section>

						<section>

							<header class="major" id="invited">
								<h2>Invited Speakers</h2>
							</header>

							<div class="row">
								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://www.ilr.cornell.edu/people/john-abowd"><img class="center" src="images/JohnAbowd.jpg" alt=""/></a></span>
									<div class="content"><p class="name">John M. Abowd</p>U.S. Census Bureau<br><br>
										<p><a href="#john">Talk details</a></p>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://users.cs.duke.edu/~ashwin/"><img class="center" src="images/ashwin.png" alt=""/></a></span>
									<div class="content"><p class="name">Ashwin Machanavajjhala</p>Duke University<br><br>
										<p><a href="#ashwin">Talk details</a></p>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://www.papernot.fr/"><img class="center" src="images/nicolas.jpg" alt=""/></a></span>
									<div class="content"><p class="name">Nicolas Papernot</p>University of Toronto<br><br>
										<p><a href="#nicolas">Talk details</a></p>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://www.comp.nus.edu.sg/~reza/"><img class="center" src="images/reza.jpg" alt=""/></a></span>
									<div class="content"><p class="name">Reza Shokri</p>National University of Singapore<br><br>
										<p><a href="#reza">Talk details</a></p>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://zstevenwu.com/"><img class="center" src="images/ZSW.jpg" alt=""/></a></span>
									<div class="content"><p class="name">Steven Wu</p>Carnegie Mellon University<br><br>
										<p><a href="#steven">Talk details</a></p>
									</div>
								</div>


								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://audramarymcmillan.wixsite.com/mysite"><img class="center" src="images/audra.png" alt=""/></a></span>
									<div class="content"><p class="name">Audra McMillan</p>Apple<br><br>
										<p><a href="#audra">Tutorial details</a></p>
									</div>
								</div>



								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://research.google/people/author35837/"><img class="center" src="images/brendan.jpg" alt=""/></a></span>
									<div class="content"><p class="name">Brendan McMahan</p>Google<br><br>
										<p><a href="#fedlearning">Tutorial details</a></p>
									</div>
								</div>

								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://scholar.google.com/citations?user=R-ndJmYAAAAJ&hl=en"><img class="center" src="images/Kallista.jpg" alt=""/></a></span>
									<div class="content"><p class="name">Kallista Bonawitz </p>Google<br><br>
										<p><a href="#fedlearning">Tutorial details</a></p>
									</div>
								</div>


								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://kairouzp.github.io/"><img class="center" src="images/peter.jpg" alt=""/></a></span>
									<div class="content"><p class="name">Peter Kairouz</p>Google<br><br>
										<p><a href="#fedlearning">Tutorial details</a></p>
									</div>
								</div>


								
							</div>


						</section>

						<section>
							<header class="major" id="pc">
								<h2>Program Committee</h2>
							</header>
							<ul>
								<li>Aws		Albarghouthi 	- University of Wisconsin-Madison</li>
								<li>Carsten	Baum			- Aarhus University</li>
								<li>Aurélien 	Bellet		- INRIA</li>
								<li>Mark	Bun				- Boston University</li>
								<li>Albert	Cheu			- Northeastern University</li>
								<li>Graham	Cormode			- University of Warwick</li>
								<li>Rachel	Cummings		- Georgia Tech</li>
								<li>Xi		He				- University of Waterloo</li>
								<li>Antti	Honkela			- University of Helsinki</li>
								<li>Mohamed Ali	Kaafar		- Macquarie University and CSIRO-Data61</li>
								<li>Kim		Laine			- Microsoft Research</li>
								<li>Yuliia	Lut				- Georgia Institute of Technology</li>
								<li> Terrence W.K.	Mak		- Georgia Institute of Technology</li>
								<li>Olga	Ohrimenko		- The University of Melbourne</li>
								<li>Catuscia	Palamidessi	- Laboratoire d'informatique de l'École polytechnique</li>
								<li>Paritosh	Ramanan		- Georgia Institute of Technology</li>
								<li>Marco	Romanelli		- INRIA</li>
								<li>Reza	Shokri			- NUS</li>
								<li>Sahib Singh				- Ford and OpenMined</li>
								<li>Vikrant	Singhal			- Northeastern University</li>
								<li>Keyu	Zhu				- Georgia Institute of Technology</li>
							</ul>
						</section>

						<section>
							<header class="major" id="chairs">
								<h2>Workshop Chairs</h2>
							</header>

							<div class="row">
								<!-- <article> -->
								<div class="col-4 col-12-medium">
									<span class="image left">
										<a href="https://www.nandofioretto.com"><img class="center" src="images/Nando.png" alt=""/></a>
									</span>
									<div class="content">
										<p class="name">Ferdinando Fioretto</p>
										Syracuse University
										<br><br>
										<p>
<!-- 											<a href="nandofioretto.com">homepage</a><br>
 -->											<a href="mailto:ffiorett@syr.edu">ffiorett@syr.edu</a>
										</p>
									</div>
								</div>
								<!-- </article> -->
								<!-- <article> -->
								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://sites.gatech.edu/pascal-van-hentenryck/"><img class="center" src="images/Pascal.png" alt=""/></a></span>
									<div class="content">
										<p class="name">Pascal Van Hentenryck</p>
										Georgia Institute of Technology
										<br><br>
										<p>
<!-- 											<a href="nandofioretto.com">homepage</a><br>
 -->											<a href="mailto:pvh@isye.gatech.edu">pvh@isye.gatech.edu</a>
										</p>
									</div>
								</div>
								<!-- </article> -->
								<!-- <article> -->
								<div class="col-4 col-12-medium">
									<span class="image left"><a href="https://sites.google.com/site/rickecon/"><img class="center" src="images/Richard.png" alt=""/></a></span>
									<div class="content">
										<p class="name">Richard W. Evans</p>
										Rice University
										<br><br>
										<p>
<!-- 											<a href="nandofioretto.com">homepage</a><br>
 -->											<a href="mailto:rwevans@rice.edu">rwevans@rice.edu</a>
										</p>
									</div>
								</div>
								<!-- </article> -->
							</div>
						</section>
				</div>
			</div>

		<!-- Sidebar -->
			<div id="sidebar">
				<div class="inner">
					<!-- Menu -->
						<nav id="menu">
							<header class="major">
								<h2>PPAI21</h2>
							</header>
							<ul>
								<li><a href="#scope">Scope</a></li>
								<li><a href="#dates">Important Dates</a></li>
								<li><a href="#submission">Submission</a></li>
								<li>
									<span class="opener">Program</span>
								<ul>
									<li><a href="#program">Schedule</a></li>
									<li><a href="#tutorials">Tutorials</a></li>
									<li><a href="#invited_talks">Invited Talks</a></li>
									<li><a href="#panel">Panel</a></li>
								</ul>
								</li>
								<li><a href="#accepted_papers">Accepted Papers</a></li>
								<li><a href="#invited">Invited Speakers</a></li> 
 								<li><a href="#pc">Program Committee</a></li>
								<li><a href="#chairs">Workshop Chairs</a></li>

<!-- 								<li><a href="#sponsors">Sponsor and Partners</a></li>
 -->							</ul>
						</nav>

					<!-- Section -->
						<section>
							<header class="major">
								<h2>Contacts</h2>
							</header>
<!-- 									<p>.</p> -->	
						<ul class="contact">
							<li class="icon solid fa-envelope"><a href="mailto:ffiorett@syr.edu,">Email chairs</a></li>
							<!-- <li class="icon brands fa-twitter"><a href="https://twitter.com/PPAI211">Twitter</a></li> -->
						</ul>
						</section>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">Website template from: <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

					</div>
				</div>

		</div>

	<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

	</body>
</html>
